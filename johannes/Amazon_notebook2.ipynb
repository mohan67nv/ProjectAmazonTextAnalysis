{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = 'C:\\\\users\\johannes\\ProjectAmazonTextAnalysis\\johannes'\n",
    "os.chdir(path)\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "import gzip\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1000\nTime : 0.10109710693359375\n"
     ]
    }
   ],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "sample_size = 1400\n",
    "\n",
    "def get_training_data(path):\n",
    "    \"\"\"\n",
    "    Get all usable data\n",
    "    :param path: path to compressed data\n",
    "    :return: panda data frame\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        i += 1\n",
    "        if i <= sample_size:\n",
    "            df[i] = d\n",
    "        else:\n",
    "            break\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(\"Step:\", i + 1)\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "# def get_test_data(path):\n",
    "#     \"\"\"\n",
    "#     Do not call this before the real test!!!!\n",
    "#     \"\"\"\n",
    "#     pass\n",
    "#     i = 0\n",
    "#     df = {}\n",
    "#     for d in parse(path):\n",
    "#         i += 1\n",
    "#         if i > 1400000:\n",
    "#             df[i] = d\n",
    "#     return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "df = get_training_data('reviews_Electronics_5.json.gz')\n",
    "\n",
    "print(\"Time :\", time.time() - start_time)\n",
    "\n",
    "df_1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_dataframe(df = df_1):\n",
    "    y = df['overall'].values\n",
    "    X = df['reviewText']\n",
    "    df = pd.DataFrame(np.column_stack((X,y)), columns = ['text', 'labels'])\n",
    "    return df\n",
    "df = fix_dataframe(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Original Review: This cable does the job but b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>How do audio cassettes load in your car's cass...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>The Nook 7&amp;#34; 8GB Wifi tablet was a Christma...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>When we first bought our bedroom tv, we looked...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>I got this as a gift about 5 months ago.  It d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Original Review: This cable does the job but b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>How do audio cassettes load in your car's cass...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>The Nook 7&amp;#34; 8GB Wifi tablet was a Christma...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>When we first bought our bedroom tv, we looked...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>I got this as a gift about 5 months ago.  It d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(df = df):\n",
    "    train_df, test_df = train_test_split(df)\n",
    "    # print(train_df.head())\n",
    "    # return pd.DataFrame(train_df, columns=['text', 'labels']), pd.DataFrame(test_df, columns=['text', 'labels'])\n",
    "    return train_df, test_df\n",
    "train_df, test_df = split_data(df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"n't\", 925), (')', 912), ('was', 910), (\"'s\", 884), ('as', 806), ('(', 789), ('can', 748), ('are', 692), ('or', 664), ('so', 660), ('be', 654), ('!', 583), ('from', 581), ('if', 576), ('do', 570), ('one', 566), ('&', 552), (';', 551), ('at', 516), ('an', 509), ('very', 479), ('all', 475), ('books', 472), ('use', 462), ('kindle', 457), ('like', 450), ('has', 442), ('just', 439), ('they', 433), ('more', 425), ('no', 414), ('me', 412), ('get', 409), ('your', 406), ('great', 393), ('would', 389), ('when', 389), ('had', 388), ('good', 385), ('screen', 383), ('than', 373), ('will', 372), ('read', 355), ('up', 343), ('about', 334), ('tv', 333), ('which', 326), ('does', 321), ('only', 318), ('there', 310), ('also', 304), ('tablet', 301), ('out', 299), ('...', 299), ('well', 292), ('n', 281), ('did', 273), ('b', 272), ('device', 271), ('other', 270), ('now', 270), ('some', 264), ('works', 262), ('what', 259), (\"''\", 257), ('much', 256), (\"'m\", 256), ('-', 255), (':', 254), ('am', 250), ('them', 249), ('book', 245), ('even', 244), ('bought', 243), ('radio', 241), ('these', 237), ('time', 237), ('buy', 233), ('because', 233), ('price', 232), ('any', 230), ('reading', 229), ('card', 228), ('by', 219), ('easy', 216), ('still', 215), ('could', 214), ('after', 214), ('really', 210), ('back', 208), (\"'ve\", 207), ('want', 206), ('$', 203), ('mount', 203), ('color', 199), ('used', 199), ('android', 195), ('battery', 194), ('better', 190), ('we', 190)]\n"
     ]
    }
   ],
   "source": [
    "# Using the standard stopwords given by nltk. Can also do feature relevance according to word frequency limits.\n",
    "# Could also test a limit for word appearance in a given percentage of texts.\n",
    "\n",
    "def find_words(df = train_df, stopword = False, word_frequency = [1000, 10]):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    \n",
    "    texts = df['text'].values\n",
    "    # dictionary = np.unique([word.lower() for text in texts for word in word_tokenize(text)])\n",
    "    # word_count = Counter([word.lower() for text in texts for word in word_tokenize(text)])\n",
    "    \n",
    "    if stopword == False:\n",
    "        word_count = Counter([word.lower() for text in texts \n",
    "                              for word in word_tokenize(text)])\n",
    "        if word_frequency != None:\n",
    "            word_count = {word: count for word, count in word_count.items() \n",
    "                          if count < word_frequency[0] and count > word_frequency[1]}            \n",
    "    elif stopword == True:\n",
    "        word_count = Counter([word.lower() \n",
    "                                for text in texts \n",
    "                                for word in word_tokenize(text) \n",
    "                                if word not in stopwords.words('english')])\n",
    "    else:\n",
    "        raise ValueError('stopword argument needs to be True/False')\n",
    "    \n",
    "    dictionary = [word for word, count in word_count.items()]\n",
    "    word_count = sorted([(word, count) for word, count in word_count.items()], key = lambda x: -x[1])\n",
    "    return word_count, dictionary\n",
    "word_freq, dictionary = find_words()\n",
    "print(word_freq[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(df = train_df ,lower_limit = 10):\n",
    "    texts = df['text'].values\n",
    "    texts_lower = []\n",
    "    for text in texts:\n",
    "        words = []\n",
    "        for word in word_tokenize(text):\n",
    "            words.append(word.lower())\n",
    "        texts_lower.append(words)\n",
    "    # print(texts_lower[:2])\n",
    "\n",
    "    bigrams = [gram for text in texts_lower for gram in ngrams(text, n=2)]\n",
    "    bigram_count = Counter(bigrams)\n",
    "    bigrams = [bigram for bigram, count in bigram_count.items() if count > lower_limit]\n",
    "    sorted_bigrams = sorted([(bigram, count) \n",
    "                             for bigram, count in bigram_count.items() \n",
    "                             if bigram in bigrams], \n",
    "                            key = lambda x: -x[1])\n",
    "    # print(sorted_bigrams[0:20])\n",
    "    return bigrams, sorted_bigrams\n",
    "    # (',', 'but) , ('do', \"n't\"), ('the', 'price'), ('.', 'if'), ('but', 'it'), ('did', \"n't\"), \n",
    "bigrams, bigram_count = get_bigrams()\n",
    "# get_bigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_dataframe(texts = train_df.text.values, \n",
    "                   words = dictionary, \n",
    "                   labels = train_df['labels'].values):\n",
    "    word_occurances = []\n",
    "    for text in texts:\n",
    "        text_occurences = np.zeros(len(words))\n",
    "        for word in word_tokenize(text):\n",
    "            word = word.lower()\n",
    "            if word in words:\n",
    "                index = words.index(word)\n",
    "                text_occurences[index] += 1\n",
    "        word_occurances.append(text_occurences)\n",
    "    \n",
    "    X_words = pd.DataFrame(np.array(word_occurances), columns = words)\n",
    "    y = labels\n",
    "    return X_words, y\n",
    "\n",
    "X_words, y = word_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('would', 'recommend')</th>\n",
       "      <th>('and', 'get')</th>\n",
       "      <th>('one', 'of')</th>\n",
       "      <th>('think', 'the')</th>\n",
       "      <th>('price', '.')</th>\n",
       "      <th>('and', 'no')</th>\n",
       "      <th>('did', 'not')</th>\n",
       "      <th>('install', '.')</th>\n",
       "      <th>('this', 'item')</th>\n",
       "      <th>('the', 'ipad')</th>\n",
       "      <th>...</th>\n",
       "      <th>('is', 'on')</th>\n",
       "      <th>('and', 'so')</th>\n",
       "      <th>('nook', 'tablet')</th>\n",
       "      <th>('but', 'i')</th>\n",
       "      <th>('if', 'they')</th>\n",
       "      <th>('into', 'the')</th>\n",
       "      <th>('.', 'once')</th>\n",
       "      <th>('from', 'the')</th>\n",
       "      <th>('i', 'did')</th>\n",
       "      <th>('in', 'and')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('would', 'recommend')</th>\n",
       "      <th>('and', 'get')</th>\n",
       "      <th>('one', 'of')</th>\n",
       "      <th>('think', 'the')</th>\n",
       "      <th>('price', '.')</th>\n",
       "      <th>('and', 'no')</th>\n",
       "      <th>('did', 'not')</th>\n",
       "      <th>('install', '.')</th>\n",
       "      <th>('this', 'item')</th>\n",
       "      <th>('the', 'ipad')</th>\n",
       "      <th>...</th>\n",
       "      <th>('is', 'on')</th>\n",
       "      <th>('and', 'so')</th>\n",
       "      <th>('nook', 'tablet')</th>\n",
       "      <th>('but', 'i')</th>\n",
       "      <th>('if', 'they')</th>\n",
       "      <th>('into', 'the')</th>\n",
       "      <th>('.', 'once')</th>\n",
       "      <th>('from', 'the')</th>\n",
       "      <th>('i', 'did')</th>\n",
       "      <th>('in', 'and')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1769 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bigram_dataframe(texts = train_df.text.values, \n",
    "                   bigrams = bigrams, \n",
    "                   labels = train_df['labels'].values):\n",
    "    bigram_occurances = []\n",
    "    for text in texts:\n",
    "        text_occurences = np.zeros(len(bigrams))\n",
    "        text_words = [word.lower() for word in word_tokenize(text)]\n",
    "        bigrams_in_text = [gram for gram in ngrams(text_words, n=2)]\n",
    "        for gram in bigrams_in_text:\n",
    "            if gram in bigrams:\n",
    "                index = bigrams.index(gram)\n",
    "                text_occurences[index] += 1\n",
    "        bigram_occurances.append(text_occurences)\n",
    "    \n",
    "    cols = [str(gram) for gram in bigrams]\n",
    "    # print(cols)\n",
    "    X_bigrams = pd.DataFrame(np.array(bigram_occurances), columns = cols)\n",
    "    y = labels\n",
    "    return X_bigrams\n",
    "# \n",
    "X_bigrams = bigram_dataframe()\n",
    "# bigram_dataframe()\n",
    "X_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050,)\n(1050, 1769)\n"
     ]
    }
   ],
   "source": [
    "print(train_df['labels'].shape)\n",
    "print(X_bigrams.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 1313)\n"
     ]
    }
   ],
   "source": [
    "print(X_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1050, 3082)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('would', 'recommend')</th>\n",
       "      <th>('and', 'get')</th>\n",
       "      <th>('one', 'of')</th>\n",
       "      <th>('think', 'the')</th>\n",
       "      <th>('price', '.')</th>\n",
       "      <th>('and', 'no')</th>\n",
       "      <th>('did', 'not')</th>\n",
       "      <th>('install', '.')</th>\n",
       "      <th>('this', 'item')</th>\n",
       "      <th>('the', 'ipad')</th>\n",
       "      <th>...</th>\n",
       "      <th>option</th>\n",
       "      <th>sold</th>\n",
       "      <th>ereaders</th>\n",
       "      <th>plug</th>\n",
       "      <th>covers</th>\n",
       "      <th>iphone</th>\n",
       "      <th>youtube</th>\n",
       "      <th>money</th>\n",
       "      <th>wire</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3082 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('would', 'recommend')</th>\n",
       "      <th>('and', 'get')</th>\n",
       "      <th>('one', 'of')</th>\n",
       "      <th>('think', 'the')</th>\n",
       "      <th>('price', '.')</th>\n",
       "      <th>('and', 'no')</th>\n",
       "      <th>('did', 'not')</th>\n",
       "      <th>('install', '.')</th>\n",
       "      <th>('this', 'item')</th>\n",
       "      <th>('the', 'ipad')</th>\n",
       "      <th>...</th>\n",
       "      <th>option</th>\n",
       "      <th>sold</th>\n",
       "      <th>ereaders</th>\n",
       "      <th>plug</th>\n",
       "      <th>covers</th>\n",
       "      <th>iphone</th>\n",
       "      <th>youtube</th>\n",
       "      <th>money</th>\n",
       "      <th>wire</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3082 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the bigrams and unigrams to one dataframe. \n",
    "X_train = pd.concat([X_bigrams, X_words], axis = 1)\n",
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}